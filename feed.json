{
    "version": "https://jsonfeed.org/version/1",
    "title": "Machine Learning &amp; Partial Differential Equations",
    "description": "",
    "home_page_url": "https://jmmachadol.github.io/blog_ml-pde",
    "feed_url": "https://jmmachadol.github.io/blog_ml-pde/feed.json",
    "user_comment": "",
    "author": {
        "name": "Jose Manuel Machado-Loaiza"
    },
    "items": [
        {
            "id": "https://jmmachadol.github.io/blog_ml-pde/busqueda-de-hiperparametros.html",
            "url": "https://jmmachadol.github.io/blog_ml-pde/busqueda-de-hiperparametros.html",
            "title": "Búsqueda de Hiperparámetros",
            "summary": "Introducción La optimización de hiperparámetros es un componente esencial del entrenamiento de modelos de aprendizaje automático, como las redes neuronales multicapa (MLP). Los hiperparámetros son configuraciones del modelo que deben ser definidas antes del entrenamiento, y pueden influir significativamente en la capacidad del modelo para&hellip;",
            "content_html": "<div id=\"content\">\n<h2>Introducción</h2>\n<p>La optimización de hiperparámetros es un componente esencial del entrenamiento de modelos de aprendizaje automático, como las redes neuronales multicapa (MLP). Los hiperparámetros son configuraciones del modelo que deben ser definidas antes del entrenamiento, y pueden influir significativamente en la capacidad del modelo para aprender de los datos y generalizar a nuevos ejemplos. En este entrada, exploramos y comparamos tres técnicas ampliamente utilizadas para optimizar hiperparámetros: Grid Search, Randomized Search y Bayesian Search.</p>\n<h2>1. Grid Search</h2>\n<p>El Grid Search, o búsqueda por cuadrícula, es una técnica de optimización de hiperparámetros que evalúa sistemáticamente todas las posibles combinaciones de hiperparámetros definidas. Aunque este enfoque exhaustivo puede ser costoso en términos de recursos computacionales, garantiza que se examine cada posible combinación de hiperparámetros, ofreciendo la posibilidad de encontrar el conjunto óptimo con un alto grado de certeza.</p>\n<p>El Grid Search es particularmente útil cuando se dispone de suficientes recursos computacionales y el espacio de búsqueda es razonablemente pequeño. Sin embargo, su eficiencia disminuye a medida que aumenta el número de hiperparámetros y sus posibles valores, ya que el tiempo y los recursos necesarios crecen exponencialmente.</p>\n<p> </p>\n<h2>2. Randomized Search</h2>\n<p>El Randomized Search, o búsqueda aleatoria, aborda algunas de las limitaciones del Grid Search al seleccionar aleatoriamente un subconjunto de combinaciones de hiperparámetros para evaluar. Esto puede resultar en una mayor eficiencia sin sacrificar demasiado la calidad de la solución encontrada.</p>\n<p>A diferencia del Grid Search, que siempre probará las mismas combinaciones de hiperparámetros, el Randomized Search puede explorar una variedad más amplia de valores, lo que puede resultar beneficioso si el espacio de hiperparámetros es muy grande o si la distribución de los valores óptimos es desconocida.</p>\n<p> </p>\n<h2>3. Bayesian Search</h2>\n<p>El Bayesian Search, o búsqueda bayesiana, es una técnica de optimización que utiliza métodos de estadística bayesiana para guiar la búsqueda de hiperparámetros. A diferencia de las técnicas anteriores, la búsqueda bayesiana utiliza los resultados de las evaluaciones anteriores para informar las elecciones de los futuros hiperparámetros a probar.</p>\n<p>La principal ventaja de la búsqueda bayesiana es que puede encontrar conjuntos óptimos de hiperparámetros más rápidamente que el Grid Search y el Randomized Search, especialmente en espacios de alta dimensión. Sin embargo, puede ser más difícil de implementar y comprender que las técnicas más simples.</p>\n<h2>Comparación y Conclusiones</h2>\n<table>\n<tbody>\n<tr>\n<th>Técnica</th>\n<th>Ventajas</th>\n<th>Desventajas</th>\n</tr>\n<tr>\n<td>Grid Search</td>\n<td>Exhaustivo, fácil de implementar y entender</td>\n<td>Costoso computacionalmente, no escalable con muchas dimensiones</td>\n</tr>\n<tr>\n<td>Randomized Search</td>\n<td>Eficiente, escalable, exploración diversa de hiperparámetros</td>\n<td>Posible falta de precisión, resultados pueden variar</td>\n</tr>\n<tr>\n<td>Bayesian Search</td>\n<td>Rápido en espacios de alta dimensión, aprende de iteraciones anteriores</td>\n<td>Más complejo, implementación puede ser desafiante</td>\n</tr>\n</tbody>\n</table>\n<p>Optimizar hiperparámetros es vital en la formación de modelos de redes neuronales. Elegir los hiperparámetros correctos puede marcar la diferencia entre un modelo mediocre y uno excepcional. Aunque las técnicas avanzadas como la búsqueda bayesiana pueden ofrecer beneficios significativos en términos de eficiencia y precisión, las técnicas más simples como el Grid Search y el Randomized Search siguen siendo valiosas y pueden ser más apropiadas en determinadas situaciones. Como siempre, la elección de la técnica dependerá del problema específico, los datos disponibles y los recursos de cómputo.</p>\n<h2>Referencias</h2>\n<ul>\n<li>Bergstra, J., &amp; Bengio, Y. (2012). Random search for hyper-parameter optimization. Journal of Machine Learning Research, 13(Feb), 281-305.</li>\n<li>Snoek, J., Larochelle, H., &amp; Adams, R. P. (2012). Practical bayesian optimization of machine learning algorithms. In Advances in neural information processing systems (pp. 2951-2959).</li>\n<li>Probst, P., Bischl, B., &amp; Boulesteix, A. L. (2019). Tunability: Importance of hyperparameters of machine learning algorithms. Journal of Machine Learning Research, 20(53), 1-32.</li>\n</ul>\n</div>",
            "author": {
                "name": "Jose Manuel Machado-Loaiza"
            },
            "tags": [
            ],
            "date_published": "2023-06-28T18:51:57-05:00",
            "date_modified": "2023-06-28T18:53:04-05:00"
        },
        {
            "id": "https://jmmachadol.github.io/blog_ml-pde/oe1.html",
            "url": "https://jmmachadol.github.io/blog_ml-pde/oe1.html",
            "title": "Teorema de Aproximación y Retropropagación",
            "summary": "Teorema de Aproximación Universal Un perceptrón multicapa (MLP) entrenado con el algoritmo de retropropagación puede ser visto como una herramienta efectiva para realizar un mapeo de entrada-salida no lineal. La relación de entrada-salida de una red define un mapeo desde un espacio de entrada euclidiano&hellip;",
            "content_html": "<div id=\"content\">\n<h2>Teorema de Aproximación Universal</h2>\n<p>Un perceptrón multicapa (MLP) entrenado con el algoritmo de retropropagación puede ser visto como una herramienta efectiva para realizar un mapeo de entrada-salida no lineal. La relación de entrada-salida de una red define un mapeo desde un espacio de entrada euclidiano <strong>m<sub>0</sub></strong>-dimensional a un espacio de salida euclidiano <strong>M</strong>-dimensional, que es infinitamente diferenciable en términos continuos si la función de activación también lo es (Cybenko, 1989).</p>\n<figure class=\"post__image\">Desde esta perspectiva de mapeo de entrada-salida, surge una pregunta fundamental: ¿cuál es el número mínimo de capas ocultas necesarias en un MLP para proporcionar una aproximación de cualquier mapeo continuo? Esta pregunta nos lleva al teorema de aproximación universal (Haykin, 2009).\n<img loading=\"lazy\"  src=\"https://jmmachadol.github.io/blog_ml-pde/media/posts/8/oe.png\" alt=\"\" width=\"1024\" height=\"768\" sizes=\"100vw\" srcset=\"https://jmmachadol.github.io/blog_ml-pde/media/posts/8/responsive/oe-xs.png 300w ,https://jmmachadol.github.io/blog_ml-pde/media/posts/8/responsive/oe-sm.png 480w ,https://jmmachadol.github.io/blog_ml-pde/media/posts/8/responsive/oe-md.png 768w ,https://jmmachadol.github.io/blog_ml-pde/media/posts/8/responsive/oe-lg.png 1024w ,https://jmmachadol.github.io/blog_ml-pde/media/posts/8/responsive/oe-xl.png 1360w ,https://jmmachadol.github.io/blog_ml-pde/media/posts/8/responsive/oe-2xl.png 1600w\"></figure>\n<p>El teorema de aproximación universal es un resultado clave en la teoría de las redes neuronales. Se establece que un MLP con una sola capa oculta puede aproximar cualquier función continua en un dominio compacto, siempre que la función de activación en la capa oculta sea una función no constante, acotada y continuamente diferenciable (Hornik, 1991). Este resultado fue extendido por Leshno et al. (1993), quienes demostraron que las redes neuronales con una función de activación no polinómica también pueden aproximar cualquier función continua.</p>\n<p>Es importante resaltar que el teorema de aproximación universal no proporciona una guía sobre la cantidad de neuronas necesarias en la capa oculta para lograr una aproximación precisa, ni proporciona una estrategia para entrenar la red para alcanzar dicha aproximación. Estos son problemas que dependen de la función específica a ser aproximada y de la arquitectura de la red neuronal en cuestión.</p>\n<h2>Implicaciones del Teorema de Aproximación Universal</h2>\n<p>El teorema de aproximación universal tiene tres implicaciones importantes:</p>\n<ol>\n<li>Las redes neuronales multicapa son capaces, en principio, de aproximar cualquier función continua, lo que indica que pueden ser utilizadas en una amplia gama de aplicaciones.</li>\n<li>Las funciones de activación no lineales son cruciales para que las redes neuronales sean capaces de aproximar efectivamente funciones complejas y no lineales.</li>\n<li>Aunque el teorema de aproximación universal establece que una sola capa oculta es suficiente, en la práctica, las redes con múltiples capas ocultas pueden ser más eficientes en términos de la cantidad de neuronas requeridas y la facilidad de entrenamiento (Goodfellow et al., 2016).</li>\n</ol>\n<h2>Algoritmo de Retropropagación</h2>\n<figure class=\"post__image\">El algoritmo de retropropagación es una técnica utilizada para entrenar redes neuronales. Se basa en el método del gradiente descendente y la optimización de una función de pérdida con respecto a los pesos de la red. Consta de dos fases: propagación hacia adelante y propagación hacia atrás (Rumelhart et al., 1986).\n<img loading=\"lazy\"  src=\"https://jmmachadol.github.io/blog_ml-pde/media/posts/8/maxresdefault.jpg\" alt=\"\" width=\"1280\" height=\"720\" sizes=\"100vw\" srcset=\"https://jmmachadol.github.io/blog_ml-pde/media/posts/8/responsive/maxresdefault-xs.jpg 300w ,https://jmmachadol.github.io/blog_ml-pde/media/posts/8/responsive/maxresdefault-sm.jpg 480w ,https://jmmachadol.github.io/blog_ml-pde/media/posts/8/responsive/maxresdefault-md.jpg 768w ,https://jmmachadol.github.io/blog_ml-pde/media/posts/8/responsive/maxresdefault-lg.jpg 1024w ,https://jmmachadol.github.io/blog_ml-pde/media/posts/8/responsive/maxresdefault-xl.jpg 1360w ,https://jmmachadol.github.io/blog_ml-pde/media/posts/8/responsive/maxresdefault-2xl.jpg 1600w\"></figure>\n<p>Durante la propagación hacia adelante, la red recibe una entrada y genera una salida. La función de pérdida, que mide la discrepancia entre la salida de la red y la salida deseada, se evalúa utilizando la salida generada. En la fase de propagación hacia atrás, se calculan las derivadas parciales de la función de pérdida con respecto a cada peso y sesgo de la red utilizando la regla de la cadena. Estas derivadas parciales se utilizan para actualizar los pesos y sesgos de la red a través del método del gradiente descendente.</p>\n<p>El proceso de retropropagación se repite hasta que se alcanza un criterio de convergencia definido, como un error de entrenamiento mínimo o un número máximo de épocas de entrenamiento.</p>\n<h2>Importancia y Pertinencia para las Redes Neuronales</h2>\n<p>Tanto el Teorema de Aproximación Universal como el Algoritmo de Retropropagación son de gran importancia y pertinencia para las redes neuronales por las siguientes razones:</p>\n<ol>\n<li>El Teorema de Aproximación Universal demuestra que las redes neuronales tienen la capacidad de aproximar cualquier función continua, lo que las convierte en herramientas poderosas para modelar y resolver problemas complejos en diversas áreas.</li>\n<li>La retropropagación es esencial para el entrenamiento de redes neuronales, permitiendo que las redes aprendan a partir de datos y mejoren su rendimiento a medida que se ajustan los pesos y parámetros.</li>\n<li>La combinación del Teorema de Aproximación Universal y la retropropagación proporciona una base teórica y práctica sólida para el diseño y entrenamiento de redes neuronales, lo que permite su aplicación en una amplia gama de problemas y tareas.</li>\n</ol>\n<h2>Referencias</h2>\n<ul>\n<li>Cybenko, G. (1989). Approximation by Superpositions of a Sigmoidal Function. Mathematics of Control, Signals, and Systems, 2, 303–314.</li>\n<li>Haykin, S. (2009). Neural Networks and Learning Machines (3rd Edition). Pearson.</li>\n<li>Hornik, K. (1991). Approximation Capabilities of Multilayer Feedforward Networks. Neural Networks, 4(2), 251–257.</li>\n<li>Leshno, M., Lin, V., Pinkus, A., &amp; Schocken, S. (1993). Multilayer feedforward networks with a nonpolynomial activation function can approximate any function. Neural Networks, 6(6), 861–867.</li>\n<li>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). Deep Learning. MIT Press.</li>\n<li>Rumelhart, D. E., Hinton, G. E., &amp; Williams, R. J. (1986). Learning representations by back-propagating errors. Nature, 323, 533–536.</li>\n</ul>\n</div>",
            "author": {
                "name": "Jose Manuel Machado-Loaiza"
            },
            "tags": [
            ],
            "date_published": "2023-06-28T18:19:16-05:00",
            "date_modified": "2023-06-28T18:52:05-05:00"
        },
        {
            "id": "https://jmmachadol.github.io/blog_ml-pde/perceptron-multicapa-una-mirada-a-las-redes-neuronales.html",
            "url": "https://jmmachadol.github.io/blog_ml-pde/perceptron-multicapa-una-mirada-a-las-redes-neuronales.html",
            "title": "Perceptrón Multicapa: una mirada a las redes neuronales",
            "summary": "Introducción al Perceptrón Multicapa (MLP) En el mundo de las redes neuronales, el perceptrón multicapa (MLP) tiene un lugar prominente. Es una arquitectura de red que ha sido fundamental para el avance de los algoritmos de aprendizaje profundo. Un MLP consiste en una serie de&hellip;",
            "content_html": "<h2>Introducción al Perceptrón Multicapa (MLP)</h2>\n<p>En el mundo de las redes neuronales, el perceptrón multicapa (MLP) tiene un lugar prominente. Es una arquitectura de red que ha sido fundamental para el avance de los algoritmos de aprendizaje profundo. Un MLP consiste en una serie de capas de nodos (o \"neuronas\"), donde cada capa se conecta a la siguiente, creando una estructura en cascada. Estas redes pueden manejar patrones complejos y no lineales, lo que las hace extremadamente útiles en una variedad de aplicaciones.</p>\n<figure><figure class=\"post__image\"><img loading=\"lazy\"  style=\"width: 806px;\" src=\"https://jmmachadol.github.io/blog_ml-pde/media/posts/7/mlp_regressor-3.jpg\" alt=\"\" height=\"387\" sizes=\"100vw\" srcset=\"https://jmmachadol.github.io/blog_ml-pde/media/posts/7/responsive/mlp_regressor-3-xs.jpg 300w ,https://jmmachadol.github.io/blog_ml-pde/media/posts/7/responsive/mlp_regressor-3-sm.jpg 480w ,https://jmmachadol.github.io/blog_ml-pde/media/posts/7/responsive/mlp_regressor-3-md.jpg 768w ,https://jmmachadol.github.io/blog_ml-pde/media/posts/7/responsive/mlp_regressor-3-lg.jpg 1024w ,https://jmmachadol.github.io/blog_ml-pde/media/posts/7/responsive/mlp_regressor-3-xl.jpg 1360w ,https://jmmachadol.github.io/blog_ml-pde/media/posts/7/responsive/mlp_regressor-3-2xl.jpg 1600w\"></figure>\n<figcaption>Figura 1: Esquema de un perceptrón multicapa con dos capas ocultas (Fuente: Haykin, 2009).</figcaption>\n</figure>\n<h2>Características del MLP</h2>\n<p>Existen varias características clave que definen un MLP (Goodfellow et al., 2016; Rumelhart et al., 1986; Haykin, 2009):</p>\n<ul>\n<li>Cada neurona en la red utiliza una función de activación que es diferenciable. Si bien las funciones de activación no lineales son comunes, también se pueden usar funciones de activación lineales en ciertos casos.</li>\n<li>La red consiste en una capa de entrada, una o más capas ocultas, y una capa de salida. Las capas ocultas son aquellas que no están directamente conectadas con las entradas ni las salidas de la red.</li>\n<li>La red muestra un alto grado de conectividad, determinado por los pesos sinápticos de la red. Las neuronas pueden conectarse de muchas formas diferentes para crear tipos especiales de redes (por ejemplo, redes convolucionales o recurrentes). En esta entrada, consideraremos que las redes están completamente conectadas, a menos que se indique lo contrario.</li>\n</ul>\n<h2>¿Qué es un Perceptrón?</h2>\n<p>Un perceptrón se puede definir como una neurona artificial que toma un conjunto de entradas y produce una única salida a través de un proceso que implica la suma ponderada de las entradas, un sesgo y una función de activación. Aunque las funciones de activación no lineales diferenciables son comunes, también se pueden emplear funciones de activación lineales en ciertos casos. Vale la pena mencionar que esta definición se refiere al comportamiento de una única neurona en la red neuronal, y en el caso de una red neuronal con múltiples salidas, la salida final pertenecerá a R<sup>m</sup>. Un perceptrón logra esto aplicando tres pasos fundamentales a las entradas (Goodfellow et al., 2016):</p>\n<ol>\n<li>Suma el producto de cada entrada con un peso correspondiente. Cada peso se puede interpretar como una medida de cuán sensible es un perceptrón a cada entrada individual.</li>\n<li>Añade un sesgo a esta suma. Este sesgo se puede interpretar como una medida de cuán activa sería una neurona si todas las entradas fueran cero.</li>\n<li>Pasa este valor a través de una función de activación.</li>\n</ol>\n<p>Por lo tanto, la activación de un perceptrón se puede representar como:</p>\n<p><strong>a = σ(Σ(x<sub>i</sub> * w<sub>i</sub>) + β)</strong></p>\n<p>donde <strong>a</strong> es la activación, <strong>σ</strong> es la función de activación, <strong>x<sub>i</sub></strong> son las entradas, <strong>w<sub>i</sub></strong> son los pesos, y <strong>β</strong> es el sesgo.</p>\n<h2>Ejemplo de Regresión con MLP</h2>\n<p>Para entender mejor cómo se puede utilizar un perceptrón multicapa, veamos un ejemplo sencillo de un problema de regresión. Utilizaremos la biblioteca scikit-learn de Python, que proporciona una implementación eficiente de MLP para la regresión (MLPRegressor).</p>\n<pre><code>\n            from sklearn.neural_network import MLPRegressor\n            from sklearn.datasets import make_regression\n            from sklearn.model_selection import train_test_split\n\n            # Generamos un dataset para regresión\n            X, y = make_regression(n_samples=200, random_state=1)\n\n            # Dividimos el dataset en conjunto de entrenamiento y prueba\n            X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n\n            # Creamos el modelo de MLP\n            regr = MLPRegressor(random_state=1, max_iter=500).fit(X_train, y_train)\n\n            # Evaluamos el modelo en el conjunto de prueba\n            score = regr.score(X_test, y_test)\n            print('Score:', score)\n        </code></pre>\n<h2>Conclusión</h2>\n<p>En resumen, el perceptrón multicapa es una herramienta potente y flexible en el campo de las redes neuronales y el aprendizaje profundo. Con sus múltiples capas de neuronas interconectadas, es capaz de aprender y representar patrones complejos y no lineales. Aunque hay mucho más que se puede explorar en relación con los MLPs, esta entrada proporciona una introducción sólida a sus conceptos fundamentales.</p>\n<h2>Referencias</h2>\n<ul>\n<li>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). Deep Learning. MIT Press.</li>\n<li>Rumelhart, D. E., Hinton, G. E., &amp; Williams, R. J. (1986). Learning representations by back-propagating errors. Nature, 323(6088), 533–536.</li>\n<li>Haykin, S. (2009). Neural Networks and Learning Machines (3rd Edition). Pearson.</li>\n<li>scikit-learn developers (2022). MLPRegressor. Retrieved from: <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html\">https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html</a></li>\n</ul>",
            "author": {
                "name": "Jose Manuel Machado-Loaiza"
            },
            "tags": [
            ],
            "date_published": "2023-06-28T17:48:23-05:00",
            "date_modified": "2023-06-28T18:38:07-05:00"
        },
        {
            "id": "https://jmmachadol.github.io/blog_ml-pde/parametros-e-hiperparametros-de-las-redes-neuronales-que-son-y-cuales-son-sus-diferencias.html",
            "url": "https://jmmachadol.github.io/blog_ml-pde/parametros-e-hiperparametros-de-las-redes-neuronales-que-son-y-cuales-son-sus-diferencias.html",
            "title": "Parámetros e hiperparámetros de las redes neuronales",
            "summary": "¿Qué son y cuáles son sus diferencias? En el campo del aprendizaje automático y las redes neuronales, los términos \"parámetros\" e \"hiperparámetros\" son a menudo fuentes de confusión. En esta entrada del blog, desentrañaremos estos conceptos, explicaremos su importancia y mostraremos sus diferencias. Los parámetros&hellip;",
            "content_html": "<div class=\"container\">\n<h2>¿Qué son y cuáles son sus diferencias?</h2>\n<p> </p>\n<p>En el campo del aprendizaje automático y las redes neuronales, los términos \"parámetros\" e \"hiperparámetros\" son a menudo fuentes de confusión. En esta entrada del blog, desentrañaremos estos conceptos, explicaremos su importancia y mostraremos sus diferencias.</p>\n<h2>¿Qué son los parámetros?</h2>\n<p>Los parámetros son las variables internas de un modelo que se ajustan durante el entrenamiento de la red neuronal. Estos incluyen los pesos y sesgos en una red neuronal. Durante el entrenamiento, el algoritmo de aprendizaje busca el valor óptimo de estos parámetros para minimizar el error de predicción del modelo. Estos parámetros son fundamentales para el rendimiento del modelo, ya que determinan la forma en que la red neuronal procesa las entradas para producir una salida. Su optimización adecuada puede marcar la diferencia entre un modelo altamente preciso y uno que apenas funciona.</p>\n<h2>¿Qué son los hiperparámetros?</h2>\n<p>Los hiperparámetros son variables que definen la estructura de la red (como el número de capas ocultas, la cantidad de nodos en cada capa) y cómo se entrena el modelo (como la tasa de aprendizaje, el número de épocas, el tamaño del lote). Los hiperparámetros son establecidos antes del entrenamiento y no se cambian durante el mismo. Estos pueden verse como los 'meta' parámetros que guían todo el proceso de aprendizaje. Los hiperparámetros correctos pueden acelerar el entrenamiento y mejorar el rendimiento final del modelo, mientras que los hiperparámetros incorrectos pueden hacer que el modelo sea lento para entrenar o incluso impida su convergencia.</p>\n<h2>Diferencias clave</h2>\n<p>La diferencia fundamental entre parámetros e hiperparámetros radica en cómo se utilizan en el proceso de aprendizaje automático:</p>\n<ul>\n<li>Los parámetros son aprendidos del conjunto de datos durante el entrenamiento del modelo. Los hiperparámetros, en cambio, se establecen antes del entrenamiento y proporcionan orientación al algoritmo de aprendizaje sobre cómo se debe realizar este proceso.</li>\n<li>Los parámetros se utilizan para hacer predicciones con el modelo, mientras que los hiperparámetros dictan la estructura del modelo y cómo se debe aprender.</li>\n</ul>\n<h2>Descripción de los hiperparámetros más comunes en redes neuronales</h2>\n<h3>Capas (layer)</h3>\n<p>Las capas se refieren a la profundidad de la red neuronal. Es un hiperparámetro que indica cuántas capas de nodos tiene una red. Más capas generalmente permite a la red aprender representaciones más complejas, pero puede llevar a sobreajuste y a un mayor tiempo de entrenamiento.</p>\n<h3>Nodos (node)</h3>\n<p>Los nodos se refieren al número de neuronas en una capa particular. Al igual que las capas, un mayor número de nodos puede permitir representaciones más complejas, pero también puede llevar a sobreajuste y a tiempos de entrenamiento más largos.</p>\n<h3>Función de Activación (activation)</h3>\n<p>La función de activación define la salida de una neurona basada en su entrada. Algunas funciones comunes incluyen la función sigmoide, tangente hiperbólica y ReLU. Cada una tiene sus propias propiedades que pueden influir en cómo una red neuronal aprende.</p>\n<h3>Solver</h3>\n<p>El solver se refiere al algoritmo de optimización utilizado para entrenar la red. Los valores comunes incluyen 'sgd' (descenso de gradiente estocástico), 'adam' y 'lbfgs'. La elección del solver puede tener un impacto significativo en la velocidad de entrenamiento y la calidad del modelo final.</p>\n<h3>Tolerancia (tol)</h3>\n<p>La tolerancia es un valor que determina cuándo se debe detener el entrenamiento. Si la mejora en la pérdida es menor que el valor de tolerancia durante un número dado de iteraciones, entonces el entrenamiento se detiene. Esto puede ayudar a evitar el sobreajuste y a acelerar el entrenamiento al evitar iteraciones innecesarias.</p>\n<h3>Tamaño del Lote (batch_size)</h3>\n<p>El tamaño del lote se refiere a cuántas muestras de entrenamiento se utilizan en una única iteración de entrenamiento. Un tamaño de lote más grande puede acelerar el entrenamiento, pero puede ser más difícil de optimizar y requerir más memoria.</p>\n<h3>Tasa de Aprendizaje Inicial (learning_rate_init)</h3>\n<p>La tasa de aprendizaje inicial es la tasa a la que se ajustan los pesos durante el entrenamiento. Una tasa de aprendizaje más alta puede llevar a un entrenamiento más rápido, pero también puede resultar en una convergencia inestable. Por otro lado, una tasa de aprendizaje más baja puede hacer que el entrenamiento sea más lento, pero puede llevar a un modelo final más preciso.</p>\n<h3>Momentum</h3>\n<p>El momentum es un término que se utiliza en los optimizadores basados en gradiente para ayudar a acelerar el entrenamiento. Agrega una fracción del cambio de peso de la iteración anterior a la actual, lo que puede ayudar a acelerar la convergencia y evitar los mínimos locales.</p>\n<h3>Tasa de Aprendizaje (learning_rate)</h3>\n<p>La tasa de aprendizaje controla cuánto cambian los pesos en respuesta a la estimación de error en cada actualización de peso. Los valores pequeños permiten que la red aprenda lentamente, reduciendo la posibilidad de saltar sobre soluciones óptimas. Los valores grandes permiten que la red aprenda rápidamente, pero con el riesgo de saltar sobre soluciones óptimas.</p>\n<h2>Conclusión</h2>\n<p>En resumen, tanto los parámetros como los hiperparámetros juegan un papel crucial en el rendimiento de las redes neuronales. La elección y ajuste cuidadoso de los hiperparámetros puede tener un impacto significativo en el rendimiento del modelo final. Aunque existe un conocimiento general sobre qué valores de hiperparámetros suelen funcionar bien, la mejor configuración puede variar dependiendo del problema específico y los datos disponibles. Por lo tanto, la experimentación y el ajuste son a menudo necesarios para encontrar la mejor configuración.</p>\n</div>",
            "author": {
                "name": "Jose Manuel Machado-Loaiza"
            },
            "tags": [
            ],
            "date_published": "2023-06-23T17:14:49-05:00",
            "date_modified": "2023-06-28T18:38:17-05:00"
        },
        {
            "id": "https://jmmachadol.github.io/blog_ml-pde/literature-review-physics-informed-machine-learning.html",
            "url": "https://jmmachadol.github.io/blog_ml-pde/literature-review-physics-informed-machine-learning.html",
            "title": "Literature review: Physics-Informed Machine Learning",
            "summary": "Literature Review: Physics-Informed Neural Networks (PINNs) Physics-Informed Neural Networks (PINNs) is an area of research that combines neural networks with physical principles to create more accurate and efficient predictive models. The PINNs approach has been applied to a range of fields, including fluid dynamics, solid&hellip;",
            "content_html": "<h1>Literature Review: Physics-Informed Neural Networks (PINNs)</h1>\n<p>Physics-Informed Neural Networks (PINNs) is an area of research that combines neural networks with physical principles to create more accurate and efficient predictive models. The PINNs approach has been applied to a range of fields, including fluid dynamics, solid mechanics, material science, geophysics, astrophysics, quantum physics, and machine learning itself.</p>\n<p>The main advantage of PINNs is that they can improve the accuracy of neural network models by incorporating prior knowledge of the underlying physics. This can help to overcome the limitations of traditional data-driven methods, which may struggle to account for physical laws and constraints.</p>\n<p>Research has shown that PINNs can be effective in a wide range of applications. In fluid dynamics, PINNs has been used to predict the behavior of complex fluid flows, such as turbulent flows, with greater accuracy than traditional computational fluid dynamics methods. PINNs has also been used to design more efficient wind turbines and optimize the shape of aircraft wings.</p>\n<p>In solid mechanics, PINNs has been used to predict the deformation and failure of materials under different loading conditions, such as the behavior of soft materials under compression. PINNs has also been applied in material science to predict the properties of novel materials with potential applications in fields such as energy storage and conversion.</p>\n<p>In geophysics, PINNs has been used to model the behavior of seismic waves and to predict the occurrence and magnitude of earthquakes. In astrophysics, PINNs has been used to study the evolution of galaxies and the behavior of dark matter. In quantum physics, PINNs has been used to simulate quantum systems with a large number of interacting particles.</p>\n<p>PINNs have also been applied to other areas of physics such as plasma physics, optical physics, acoustics, and thermal transport. For example, in plasma physics, PINNs have been used to predict the behavior of plasma instabilities in fusion reactors. In optical physics, PINNs have been used to design novel optical devices with specific functionalities. In acoustics, PINNs have been used to predict the sound field and the propagation of sound waves in complex geometries. In thermal transport, PINNs have been used to design more efficient heat exchangers and predict the temperature distribution in electronic devices.</p>\n<p>Despite the potential benefits of PINNs, there are also challenges associated with their implementation. One of the main challenges is choosing the structure of the neural network model and ensuring that it is compatible with the underlying physics. Another challenge is obtaining high-quality training data that captures the relevant physical processes. Additionally, the interpretability and robustness of PINN models need further research.</p>\n<p>Overall, the literature suggests that PINNs is a promising research area that has the potential to revolutionize many fields of science and engineering. Further research is needed to refine PINNs techniques and to investigate their full potential in a wide range of applications.</p>\n<h2>Relation of PINNs with Computational Mechanics</h2>\n<p>Physics-Informed Neural Networks (PINNs) are a natural extension of classical computational mechanics methods and are closely related to the field of computational mechanics. Computational mechanics is a discipline that uses mathematical modeling and numerical analysis techniques to solve problems in mechanics, including fluid dynamics, solid mechanics, and structural mechanics.</p>\n<p>The development of PINNs is driven by the need to overcome some of the limitations of traditional computational mechanics methods, which can be computationally expensive and require a large amount of training data to be accurate. PINNs address these limitations by incorporating prior knowledge of the underlying physical principles into the neural network architecture, allowing for more efficient and accurate predictions of mechanical systems.</p>\n<p>PINNs have been used in solid mechanics to predict the deformation and failure of materials under different loading conditions, such as the behavior of soft materials under compression. In addition, PINNs have been used to simulate the dynamics of fluids, such as turbulent flows, which are notoriously difficult to model using traditional computational fluid dynamics methods.</p>\n<p>The relationship between PINNs and computational mechanics is mutually beneficial. While PINNs can provide more accurate and efficient predictions, computational mechanics can provide the necessary physical principles and constraints to guide the development of PINN models. As a result, PINNs have the potential to greatly enhance the predictive capabilities of computational mechanics methods in a wide range of fields.</p>\n<h3>References</h3>\n<ul>\n<li>Raissi, M., Perdikaris, P., &amp; Karniadakis, G. E. (2019). Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. Journal of Computational Physics, 378, 686-707.</li>\n<li>Wang, L., Zhang, X., &amp; Zuo, L. (2020). Recent advances in physics-informed neural networks for scientific computing. Computational Mechanics, 66(2), 357-378.</li>\n<li>Zhang, Y., Han, J., &amp; Xiao, H. (2020). A review of physics-informed neural networks: Methods, theory, and applications. Computational Mechanics, 66(6), 1125-1154.</li>\n</ul>",
            "author": {
                "name": "Jose Manuel Machado-Loaiza"
            },
            "tags": [
                   "Review",
                   "Machine learning"
            ],
            "date_published": "2023-02-17T09:15:00-05:00",
            "date_modified": "2023-02-28T15:27:42-05:00"
        },
        {
            "id": "https://jmmachadol.github.io/blog_ml-pde/how-to-do-a-literature-review-my-experience-in-reviewing-the-physics-informed-neural-networks-literature-and-some-practical-advice.html",
            "url": "https://jmmachadol.github.io/blog_ml-pde/how-to-do-a-literature-review-my-experience-in-reviewing-the-physics-informed-neural-networks-literature-and-some-practical-advice.html",
            "title": "My experience doing a literature review: some practical advice",
            "summary": "A literature review is an essential component of any research project, as it provides an overview of the current state of knowledge in a particular field. By identifying, selecting, and evaluating relevant literature, a literature review helps to establish the context of a research topic&hellip;",
            "content_html": "<p>A literature review is an essential component of any research project, as it provides an overview of the current state of knowledge in a particular field. By identifying, selecting, and evaluating relevant literature, a literature review helps to establish the context of a research topic and to identify gaps in the existing body of knowledge.</p>\n<h6>What is Literature?</h6>\n<p>When we talk about literature, we are referring to the works that researchers consult to understand and investigate a particular field. This can include academic books, professional journals, conference proceedings, theses, research reports, and electronic databases. Literature reviews are also useful for identifying other works by the same researchers, which can help to build a more comprehensive understanding of a particular research topic.</p>\n<h6>The Benefits of a Literature Review</h6>\n<p>A good literature review can help to answer important questions about a research topic, such as why it is necessary to study a particular problem and what assumptions need to be tested. By providing a historical context for a research topic, a literature review can also help to establish the importance of a particular problem and identify gaps in existing research. Furthermore, by summarizing and integrating individual findings, a literature review can help to address broader, integrative questions about a particular topic.</p>\n<h6>Steps for Conducting a Literature Review</h6>\n<p>There are several key steps involved in conducting a literature review:</p>\n<ol>\n<li>\n<p class=\"dropcap\">Scoping: This involves familiarizing oneself with the literature, identifying research questions, and identifying important contributions to scientific knowledge.</p>\n</li>\n<li>\n<p class=\"dropcap\">Planning: Once research questions have been identified, the search criteria are established. This includes considerations such as terminology, research design, target audience, and time frame.</p>\n</li>\n<li>\n<p class=\"dropcap\">Searching: Databases such as Scopus, Google Scholar, arXiv, Web of Science, Research Rabbit, and Connected Papers are used to find papers related to the research field.</p>\n</li>\n<li>\n<p class=\"dropcap\">Screening: A bibliographic manager, such as Zotero, is used to keep track of references and citation managers. Files and directories are named using appropriate naming conventions, such as using an underscore to separate the year of publication, authors, and title.</p>\n</li>\n<li>\n<p class=\"dropcap\">Eligibility: Relationships with other published works are established, and the validity of assumptions and the contribution of the articles are considered.</p>\n</li>\n</ol>\n<p><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">Therefore, literature reviews are an essential component of any research project. By providing an overview of the existing state of knowledge in a particular field, literature reviews help to establish the context of a research topic, identify gaps in existing research, and address broader, integrative questions about a particular topic. By following the steps outlined above, researchers can ensure that their literature reviews are comprehensive, rigorous, and useful for building knowledge in their chosen field.</span></p>\n<hr>\n<p>Basic steps I followed for the literature review of my project:</p>\n<p>1. Finding papers</p>\n<p>Using the bibliographic databases available at the university (Web of Science, Scopus, etc.), I started my first approach to the topic of machine learning applications and their uses in fields such as differential equations, neural networks, and computational mechanics. To do this, it is crucial to use a search equation and refine/filter the results according to one's particular interest. Another very good option is to use connectedpapers.com, whose tool allows you to find the similarity between scientific publications related to an entry paper.</p>\n<p>At this step, it is very helpful to review review-type scientific articles.</p>\n<p>2. Storing papers</p>\n<p>In this step, it is crucial to have a repository where you can store all the papers you are reading and have version control available. Zotero is an incredible tool because, in addition to being open-source, it allows you to export references in a .bib file and synchronize it with other software such as Mendeley. Additionally, it allows you to take notes and annotations on the paper itself.</p>\n<p>3. Reading the paper</p>\n<p>I recommend reading \"How to Read a Paper\" from the Department of Electrical Engineering, Stanford University, 2016 (available at <a href=\"https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf\">https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf</a>)</p>\n<p>The publication \"How to Read a Paper\" provides a practical guide to help readers understand and analyze scientific articles. The article suggests a number of steps to be followed when reading a paper, including identifying the research problem, reviewing the relevant literature, evaluating the methodology used, interpreting the results, and critically evaluating the work.</p>\n<p>Additionally, the publication provides useful tips for maximizing reading efficiency, such as active reading, note-taking, defining vocabulary, and using additional sources to complement understanding of the topic. The importance of clear and effective communication in papers is highlighted, and authors are suggested to follow certain writing guidelines to ensure their work is accessible and understandable to readers.</p>\n<p>Overall, the publication offers a complete set of tools and strategies to help readers navigate scientific papers and better understand the research presented.</p>\n<p>4. Writing down the main ideas of the paper:</p>\n<p>Create notes, questions, try to prioritize the ideas presented in the text. What is the big picture? And finally, how can said paper contribute to the literature review you are conducting?</p>\n<hr>\n<h1>Software for Literature Review</h1>\n<p>Here are some useful software for doing literature review that I have used in my research:</p>\n<ol>\n<li>\n<p>Zotero: Zotero is a free and open-source reference management software that allows you to collect, organize, and share research sources. It is compatible with Windows, Mac, and Linux, and integrates with various web browsers. One of its benefits is that it allows you to easily add references to your library and automatically generates citations and bibliographies.</p>\n</li>\n<li>\n<p>Mendeley: Mendeley is another reference management software that allows you to organize and cite sources, and collaborate with others. It has a user-friendly interface, and you can easily import PDFs, annotate them, and generate citations and bibliographies. It also has a social networking feature, allowing you to discover and connect with other researchers.</p>\n</li>\n<li>\n<p>ConnectedPapers.com: is a web-based tool designed to help researchers explore and navigate the academic literature. The tool works by leveraging citation data to create a visual network of related papers, which allows users to identify and explore papers that are semantically similar to their research interests.</p>\n<p>The benefits of using ConnectedPapers.com include its ability to help users discover papers they might have otherwise missed, its ability to help users identify the most important and influential papers on a given topic, and its ability to help users explore new research areas and identify potential collaborations. The tool is also free to use and does not require any downloads or installations, making it accessible to anyone with an internet connection.</p>\n</li>\n<li>\n<p>ResearchRabbit: ResearchRabbit is a free web-based software that assists researchers with organizing and managing their literature review process. The software allows users to create and organize their own personal library of research papers, as well as annotate and highlight sections of papers directly within the platform. Additionally, ResearchRabbit can automatically extract citation information from PDF files, saving time and reducing the likelihood of error.</p>\n</li>\n<li>\n<p>Rayyan: Rayyan is a web and mobile app designed to help researchers and students with systematic reviews and literature reviews. It allows users to import and screen large volumes of literature, and collaboratively work with others to identify relevant studies. The platform offers features like exclusion/inclusion criteria, tagging, and the ability to export references to other software. Rayyan also has a machine learning-based classifier that helps predict which studies are relevant and which are not, making the screening process faster and more efficient. Overall, Rayyan is a useful tool for those involved in literature reviews, systematic reviews, and other types of research that require large amounts of literature to be reviewed and organized.</p>\n</li>\n</ol>",
            "author": {
                "name": "Jose Manuel Machado-Loaiza"
            },
            "tags": [
                   "Review"
            ],
            "date_published": "2023-02-16T13:29:00-05:00",
            "date_modified": "2023-02-28T15:27:50-05:00"
        }
    ]
}
